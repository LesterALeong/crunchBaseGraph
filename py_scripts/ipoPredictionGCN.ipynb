{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPO Prediction of Using Graph Convolutional Neural Networks\n",
    "## By Parker Erickson\n",
    "\n",
    "In this notebook, we will install and run queries on a TigerGraph database to collect data from their Crunchbase Knowledge Graph demo and then pipe this data into a Graph Convolutional Neural Network (GCN) to predict whether or not a company will IPO. The performance of the GCN is not astounding, but we will explore why this is due to the very nature of the dataset and some of the simplifications I make. Other models may fair better, although these avenues haven't been explored yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TigerGraph Setup\n",
    "\n",
    "We will be installing the queries found in ../db_scripts onto the TigerGraph database. This will create a REST endpoint that the package pyTigerGraph will request from in order to grab the data for the GCN. If you haven't already done so, create a free TigerGraph cloud instance of the CrunchBase knowledge graph demo. Then, configure your gradle-local.properties file and get a SSL certificate from the server following the directions found [here](https://medium.com/@jon.herke/getting-started-with-giraffle-on-tigergraph-cloud-970ead739943). Then, we will be all set to use gradle and Giraffle to install the necessary queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/parker/crunchbaseGraph\n",
      "\n",
      "> Configure project :\n",
      "GSQL Plugin successfully applied to crunchbaseGraph\n",
      "\n",
      "> Task :tasks\n",
      "\n",
      "------------------------------------------------------------\n",
      "Tasks runnable from root project\n",
      "------------------------------------------------------------\n",
      "\n",
      "Build tasks\n",
      "-----------\n",
      "gsqlCopySources - Copy gsql scripts from input directory to build directory prior to execution.\n",
      "\n",
      "Build Setup tasks\n",
      "-----------------\n",
      "init - Initializes a new Gradle build.\n",
      "wrapper - Generates Gradle wrapper files.\n",
      "\n",
      "GSQL Interactive tasks\n",
      "----------------------\n",
      "gsqlShell - Run an interactive gsql shell session\n",
      "\n",
      "GSQL Project Wizard tasks\n",
      "-------------------------\n",
      "gsqlNewProject - Create scaffolding for new project\n",
      "\n",
      "Help tasks\n",
      "----------\n",
      "buildEnvironment - Displays all buildscript dependencies declared in root project 'crunchbaseGraph'.\n",
      "components - Displays the components produced by root project 'crunchbaseGraph'. [incubating]\n",
      "dependencies - Displays all dependencies declared in root project 'crunchbaseGraph'.\n",
      "dependencyInsight - Displays the insight into a specific dependency in root project 'crunchbaseGraph'.\n",
      "dependentComponents - Displays the dependent components of components in root project 'crunchbaseGraph'. [incubating]\n",
      "help - Displays a help message.\n",
      "kotlinDslAccessorsReport - Prints the Kotlin code for accessing the currently available project extensions and conventions.\n",
      "model - Displays the configuration model of root project 'crunchbaseGraph'. [incubating]\n",
      "outgoingVariants - Displays the outgoing variants of root project 'crunchbaseGraph'.\n",
      "projects - Displays the sub-projects of root project 'crunchbaseGraph'.\n",
      "properties - Displays the properties of root project 'crunchbaseGraph'.\n",
      "tasks - Displays the tasks runnable from root project 'crunchbaseGraph'.\n",
      "\n",
      "Tigergraph Authentication tasks\n",
      "-------------------------------\n",
      "gsqlDeleteToken - Uses Tigergraph's REST end point to delete an OAUTH token\n",
      "gsqlToken - Uses Tigergraph's REST endpoint to obtain an OAUTH token\n",
      "\n",
      "Tigergraph Queries tasks\n",
      "------------------------\n",
      "createCompanyLinks - Creates the companyLinks query\n",
      "createGetAllCompanies - Creates the getAllCompanies query\n",
      "createGetAllIpo - Creates the getAllIpo query\n",
      "installCompanyLinks - Installs the companyLinks query\n",
      "installGetAllCompanies - Installs the getAllCompanies query\n",
      "installGetAllIpo - Installs the getAllIpo query\n",
      "\n",
      "To see all tasks and more detail, run gradle tasks --all\n",
      "\n",
      "To see more detail about a task, run gradle help --task <task>\n",
      "\n",
      "BUILD SUCCESSFUL in 10s\n",
      "1 actionable task: 1 executed\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "!gradle tasks --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Configure project :\n",
      "GSQL Plugin successfully applied to crunchbaseGraph\n",
      "\n",
      "> Task :gsqlCopySources\n",
      "\n",
      "> Task :createCompanyLinks\n",
      "Supported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\n",
      "You may use 'GSQL_CLIENT_VERSION=v? java ...' or \n",
      "    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n",
      "========================\n",
      "Trying version: v2_5_2\n",
      "Connecting to crunchml.i.tgcloud.io:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "Using graph 'CrunchBasePre_2013'\n",
      "The query companyLinks has been added!\n",
      "\n",
      "BUILD SUCCESSFUL in 3s\n",
      "2 actionable tasks: 2 executed\n",
      "\u001b[m\n",
      "> Configure project :\n",
      "GSQL Plugin successfully applied to crunchbaseGraph\n",
      "\n",
      "> Task :gsqlCopySources UP-TO-DATE\n",
      "\n",
      "> Task :installCompanyLinks\n",
      "Supported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\n",
      "You may use 'GSQL_CLIENT_VERSION=v? java ...' or \n",
      "    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n",
      "========================\n",
      "Trying version: v2_5_2\n",
      "Connecting to crunchml.i.tgcloud.io:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "Using graph 'CrunchBasePre_2013'\n",
      "Start installing queries, about 1 minute ...\n",
      "companyLinks query: curl -X GET 'https://127.0.0.1:9000/query/CrunchBasePre_2013/companyLinks'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "\n",
      "[=================================================================] 100% (1/1) \n",
      "\n",
      "BUILD SUCCESSFUL in 46s\n",
      "2 actionable tasks: 1 executed, 1 up-to-date\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "!gradle createCompanyLinks --console=plain\n",
    "!gradle installCompanyLinks --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Configure project :\n",
      "GSQL Plugin successfully applied to crunchbaseGraph\n",
      "\n",
      "> Task :gsqlCopySources UP-TO-DATE\n",
      "\n",
      "> Task :createGetAllIpo\n",
      "Supported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\n",
      "You may use 'GSQL_CLIENT_VERSION=v? java ...' or \n",
      "    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n",
      "========================\n",
      "Trying version: v2_5_2\n",
      "Connecting to crunchml.i.tgcloud.io:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "Using graph 'CrunchBasePre_2013'\n",
      "The query getAllIpo has been added!\n",
      "\n",
      "BUILD SUCCESSFUL in 3s\n",
      "2 actionable tasks: 1 executed, 1 up-to-date\n",
      "\u001b[m\n",
      "> Configure project :\n",
      "GSQL Plugin successfully applied to crunchbaseGraph\n",
      "\n",
      "> Task :gsqlCopySources UP-TO-DATE\n",
      "\n",
      "> Task :installGetAllIpo\n",
      "Supported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\n",
      "You may use 'GSQL_CLIENT_VERSION=v? java ...' or \n",
      "    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n",
      "========================\n",
      "Trying version: v2_5_2\n",
      "Connecting to crunchml.i.tgcloud.io:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "Using graph 'CrunchBasePre_2013'\n",
      "Start installing queries, about 1 minute ...\n",
      "getAllIpo query: curl -X GET 'https://127.0.0.1:9000/query/CrunchBasePre_2013/getAllIpo'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "\n",
      "[=================================================================] 100% (1/1) \n",
      "\n",
      "BUILD SUCCESSFUL in 31s\n",
      "2 actionable tasks: 1 executed, 1 up-to-date\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "!gradle createGetAllIpo --console=plain\n",
    "!gradle installGetAllIpo --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "> Configure project :\n",
      "GSQL Plugin successfully applied to crunchbaseGraph\n",
      "\n",
      "> Task :gsqlCopySources UP-TO-DATE\n",
      "\n",
      "> Task :createGetAllCompanies\n",
      "Supported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\n",
      "You may use 'GSQL_CLIENT_VERSION=v? java ...' or \n",
      "    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n",
      "========================\n",
      "Trying version: v2_5_2\n",
      "Connecting to crunchml.i.tgcloud.io:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "Using graph 'CrunchBasePre_2013'\n",
      "The query getAllCompanies has been added!\n",
      "\n",
      "BUILD SUCCESSFUL in 3s\n",
      "2 actionable tasks: 1 executed, 1 up-to-date\n",
      "\u001b[m\n",
      "> Configure project :\n",
      "GSQL Plugin successfully applied to crunchbaseGraph\n",
      "\n",
      "> Task :gsqlCopySources UP-TO-DATE\n",
      "\n",
      "> Task :installGetAllCompanies\n",
      "Supported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\n",
      "You may use 'GSQL_CLIENT_VERSION=v? java ...' or \n",
      "    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n",
      "========================\n",
      "Trying version: v2_5_2\n",
      "Connecting to crunchml.i.tgcloud.io:14240\n",
      "If there is any relative path, it is relative to tigergraph/dev/gdk/gsql\n",
      "Using graph 'CrunchBasePre_2013'\n",
      "Start installing queries, about 1 minute ...\n",
      "getAllCompanies query: curl -X GET 'https://127.0.0.1:9000/query/CrunchBasePre_2013/getAllCompanies'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n",
      "\n",
      "[=================================================================] 100% (1/1) \n",
      "\n",
      "BUILD SUCCESSFUL in 31s\n",
      "2 actionable tasks: 1 executed, 1 up-to-date\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "!gradle createGetAllCompanies --console=plain\n",
    "!gradle installGetAllCompanies --console=plain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTigerGraph as tg \n",
    "import cfg\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyTigerGraph as tg\n",
    "import dgl\n",
    "import networkx as nx\n",
    "from heapq import nlargest, nsmallest\n",
    "\n",
    "from gcn import GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Connection to Database and Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = tg.TigerGraphConnection(ipAddress=\"https://crunchml.i.tgcloud.io\", graphname=\"CrunchBasePre_2013\", password=cfg.password, apiToken=cfg.token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Edges Between Companies\n",
    "\n",
    "The cell below runs the query companyLinks, and then formats each edge into a tuple (src, destination). Unfortunately, due to both memory constraints as well as the imbalanced nature of the dataset, we will not use all of the edges in the graph, and instead sample nodes and then search this list for edges between the nodes.\n",
    "\n",
    "#### **Assumption Alert:** We oversimplify the graph here. The query returns pairs of companies that have something in common. This hurts accuracy (a lot). Where TigerGraph comes in is the ease of data extraction, as there are no JOIN operations to create these links between companies.\n",
    "* Note: It is possible to create a GCN that has multiple types of verticies, (known as a Relational Graph Convolutional Notebook) but it is more complex. A good way to get started is to simplify until you only have relations between the same type of thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('footballunited', 'phuser'), ('morningpapers', 'phuser'), ('phuser', 'footballunited')]\n"
     ]
    }
   ],
   "source": [
    "edges = [(thing[\"src\"], thing[\"dest\"]) for thing in conn.runInstalledQuery(\"companyLinks\", {}, sizeLimit=512000000, timeout=320000)[\"results\"][0][\"@@tupleRecords\"]]\n",
    "print(edges[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the List of IPOed Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting IPOed List\n",
      "Getting Non IPOed List\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting IPOed List\")\n",
    "ipoed = list(set([thing[\"src\"] for thing in conn.runInstalledQuery(\"getAllIpo\", {}, sizeLimit=512000000, timeout=320000)[\"results\"][0][\"@@tupleRecords\"]]) - set(['']))\n",
    "print(\"Getting Non IPOed List\")\n",
    "nonipo = list(set([thing[\"src\"] for thing in conn.runInstalledQuery(\"getAllCompanies\", {}, sizeLimit=512000000, timeout=320000)[\"results\"][0][\"@@tupleRecords\"]]) - set(ipoed) - set(['']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Over-Sampled IPO Graph\n",
    "\n",
    "The code blocks below sample a number of nodes from each the IPOed list and the non-IPO list and determines what edges there are between the sampled nodes. Unfortunately, due to the large number of nodes in the complete graph, the number of edges in the sampled graph is quite small. This lack of edges contributes to the mediocre and highly variant performance of the following GCN. Other graph machine learning approaches such as node2vec might fair better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IPOs:  1238\n",
      "Total number of nodes:  2000\n",
      "2000\n",
      "Computing edges\n",
      "1065\n",
      "[('aspen technology', 'carbonite'), ('zinio', 'aol'), ('exact sciences', 'bind therapeutics')]\n"
     ]
    }
   ],
   "source": [
    "numberofnodes = 1000\n",
    "\n",
    "print(\"Number of IPOs: \", len(ipoed))\n",
    "ipoedsample = random.choices(ipoed, k=numberofnodes)\n",
    "noniposample = random.choices(nonipo, k=numberofnodes)\n",
    "print(\"Total number of nodes: \", len(noniposample)+len(ipoedsample))\n",
    "\n",
    "allNodes = noniposample+ipoedsample\n",
    "\n",
    "print(len(allNodes))\n",
    "\n",
    "\n",
    "finalEdges = []\n",
    "\n",
    "print(\"Computing edges\")\n",
    "for edge in edges:\n",
    "    if edge[0] in allNodes and edge[1] in allNodes:\n",
    "            finalEdges.append(edge)\n",
    "\n",
    "print(len(finalEdges))\n",
    "print(finalEdges[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Edges:  1065\n",
      "[(1652, 1595), (218, 1856), (1059, 1529), (1529, 1059), (1073, 1706)]\n"
     ]
    }
   ],
   "source": [
    "compToNum = {} # translation dictionary for company name to number (for dgl)\n",
    "numToComp = {} # translation dictionary for number to company name\n",
    "\n",
    "numericalNodes = []\n",
    "\n",
    "for i in range(0, len(allNodes)):\n",
    "    compToNum[allNodes[i]] = i\n",
    "    numericalNodes.append(i)\n",
    "    numToComp[i] = allNodes[i]\n",
    "\n",
    "def createEdgeList(result): # returns tuple of number version of edge\n",
    "    fromKey = compToNum[result[0]]\n",
    "    toKey = compToNum[result[1]]\n",
    "    return (fromKey, toKey)\n",
    "\n",
    "edges = [createEdgeList(thing) for thing in finalEdges]\n",
    "print(\"Number of Edges: \", len(edges))\n",
    "print(edges[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_nodes_from(numericalNodes)\n",
    "g.add_edges_from(edges)\n",
    "\n",
    "\n",
    "G = dgl.DGLGraph(g) # Convert networkx graph to a graph that DGL can work on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding of Node Features\n",
    "We one-hot encode the features of the verticies in the graph. Feature assignment can be done a multitude of different ways, this is just the fastest and easiest.\n",
    "\n",
    "If you had a graph of documents for example, you could run doc2vec on those documents to create a feature vector and create the feature matrix by concatenating those together.\n",
    "\n",
    "Another possiblity is that you have a graph of songs, artists, albums, etc. and you could use tempo, max volume, minimum volume, length, and other numerical descriptions of the song to create the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "G.ndata[\"feat\"] = torch.eye(G.number_of_nodes())\n",
    "\n",
    "print(G.nodes[2].data['feat'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Neural Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 200\n",
    "learningRate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Neural Network and Labelling Relevant Verticies\n",
    "\n",
    "Here, we create the GCN. A two-layered GCN appears to work better than deeper networks, and this is further corroborated by the fact [this](https://arxiv.org/abs/1609.02907) paper only used a two-layered one. We also label the wanted and unwanted verticies and setup the optimizer. Since the GCN is a semi-supervised algorithm, we do not label all of the nodes to their correct classes before training - only two are needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "compIPO = 0\n",
    "compNonIPO = 0\n",
    "i = 0\n",
    "while((not(compIPO) or not(compNonIPO)) and (i<G.number_of_nodes())):\n",
    "    if numToComp[i] in ipoed:\n",
    "        compIPO = i\n",
    "    else:\n",
    "        compNonIPO = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GCN(G.number_of_nodes(), 32, 2) #Two layer GCN\n",
    "inputs = G.ndata[\"feat\"]\n",
    "labeled_nodes = torch.tensor([compNonIPO, compIPO])  # only the liked movies and the disliked movies are labelled\n",
    "labels = torch.tensor([0, 1])  # their labels are different\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GCN\n",
    "\n",
    "Below is the training loop that actually trains the GCN. Unlike many traditional deep learning architectures, GCNs don't always need that much training or as large of data sets due to their exploitation of the *structure* of the data, as opposed to only the features of the data.\n",
    "* Note: due to the randomized initial values of the weights in the neural network and our lack of a very well-connected graph, sometimes models don't work very well, or their loss gets stuck at a relatively large number. If that happens, just stop and restart the training process (also rerun the cell above to reset the weights) and hope for better luck! Alternatively, you can run more epochs in hopes of eventually getting out of the rut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 6.976e-01\n",
      "Epoch 1 | Loss: 6.967e-01\n",
      "Epoch 2 | Loss: 6.959e-01\n",
      "Epoch 3 | Loss: 6.953e-01\n",
      "Epoch 4 | Loss: 6.947e-01\n",
      "Epoch 5 | Loss: 6.942e-01\n",
      "Epoch 6 | Loss: 6.938e-01\n",
      "Epoch 7 | Loss: 6.935e-01\n",
      "Epoch 8 | Loss: 6.933e-01\n",
      "Epoch 9 | Loss: 6.932e-01\n",
      "Epoch 10 | Loss: 6.932e-01\n",
      "Epoch 11 | Loss: 6.932e-01\n",
      "Epoch 12 | Loss: 6.932e-01\n",
      "Epoch 13 | Loss: 6.933e-01\n",
      "Epoch 14 | Loss: 6.933e-01\n",
      "Epoch 15 | Loss: 6.934e-01\n",
      "Epoch 16 | Loss: 6.935e-01\n",
      "Epoch 17 | Loss: 6.935e-01\n",
      "Epoch 18 | Loss: 6.935e-01\n",
      "Epoch 19 | Loss: 6.935e-01\n",
      "Epoch 20 | Loss: 6.935e-01\n",
      "Epoch 21 | Loss: 6.934e-01\n",
      "Epoch 22 | Loss: 6.934e-01\n",
      "Epoch 23 | Loss: 6.934e-01\n",
      "Epoch 24 | Loss: 6.933e-01\n",
      "Epoch 25 | Loss: 6.933e-01\n",
      "Epoch 26 | Loss: 6.932e-01\n",
      "Epoch 27 | Loss: 6.932e-01\n",
      "Epoch 28 | Loss: 6.932e-01\n",
      "Epoch 29 | Loss: 6.932e-01\n",
      "Epoch 30 | Loss: 6.931e-01\n",
      "Epoch 31 | Loss: 6.932e-01\n",
      "Epoch 32 | Loss: 6.932e-01\n",
      "Epoch 33 | Loss: 6.932e-01\n",
      "Epoch 34 | Loss: 6.932e-01\n",
      "Epoch 35 | Loss: 6.932e-01\n",
      "Epoch 36 | Loss: 6.932e-01\n",
      "Epoch 37 | Loss: 6.932e-01\n",
      "Epoch 38 | Loss: 6.932e-01\n",
      "Epoch 39 | Loss: 6.932e-01\n",
      "Epoch 40 | Loss: 6.932e-01\n",
      "Epoch 41 | Loss: 6.932e-01\n",
      "Epoch 42 | Loss: 6.932e-01\n",
      "Epoch 43 | Loss: 6.932e-01\n",
      "Epoch 44 | Loss: 6.932e-01\n",
      "Epoch 45 | Loss: 6.932e-01\n",
      "Epoch 46 | Loss: 6.931e-01\n",
      "Epoch 47 | Loss: 6.931e-01\n",
      "Epoch 48 | Loss: 6.931e-01\n",
      "Epoch 49 | Loss: 6.931e-01\n",
      "Epoch 50 | Loss: 6.931e-01\n",
      "Epoch 51 | Loss: 6.932e-01\n",
      "Epoch 52 | Loss: 6.932e-01\n",
      "Epoch 53 | Loss: 6.932e-01\n",
      "Epoch 54 | Loss: 6.932e-01\n",
      "Epoch 55 | Loss: 6.932e-01\n",
      "Epoch 56 | Loss: 6.932e-01\n",
      "Epoch 57 | Loss: 6.932e-01\n",
      "Epoch 58 | Loss: 6.932e-01\n",
      "Epoch 59 | Loss: 6.932e-01\n",
      "Epoch 60 | Loss: 6.932e-01\n",
      "Epoch 61 | Loss: 6.931e-01\n",
      "Epoch 62 | Loss: 6.931e-01\n",
      "Epoch 63 | Loss: 6.931e-01\n",
      "Epoch 64 | Loss: 6.931e-01\n",
      "Epoch 65 | Loss: 6.931e-01\n",
      "Epoch 66 | Loss: 6.931e-01\n",
      "Epoch 67 | Loss: 6.931e-01\n",
      "Epoch 68 | Loss: 6.931e-01\n",
      "Epoch 69 | Loss: 6.931e-01\n",
      "Epoch 70 | Loss: 6.931e-01\n",
      "Epoch 71 | Loss: 6.931e-01\n",
      "Epoch 72 | Loss: 6.931e-01\n",
      "Epoch 73 | Loss: 6.931e-01\n",
      "Epoch 74 | Loss: 6.931e-01\n",
      "Epoch 75 | Loss: 6.931e-01\n",
      "Epoch 76 | Loss: 6.931e-01\n",
      "Epoch 77 | Loss: 6.931e-01\n",
      "Epoch 78 | Loss: 6.931e-01\n",
      "Epoch 79 | Loss: 6.931e-01\n",
      "Epoch 80 | Loss: 6.931e-01\n",
      "Epoch 81 | Loss: 6.931e-01\n",
      "Epoch 82 | Loss: 6.931e-01\n",
      "Epoch 83 | Loss: 6.931e-01\n",
      "Epoch 84 | Loss: 6.931e-01\n",
      "Epoch 85 | Loss: 6.931e-01\n",
      "Epoch 86 | Loss: 6.931e-01\n",
      "Epoch 87 | Loss: 6.931e-01\n",
      "Epoch 88 | Loss: 6.931e-01\n",
      "Epoch 89 | Loss: 6.931e-01\n",
      "Epoch 90 | Loss: 6.931e-01\n",
      "Epoch 91 | Loss: 6.931e-01\n",
      "Epoch 92 | Loss: 6.931e-01\n",
      "Epoch 93 | Loss: 6.931e-01\n",
      "Epoch 94 | Loss: 6.931e-01\n",
      "Epoch 95 | Loss: 6.931e-01\n",
      "Epoch 96 | Loss: 6.931e-01\n",
      "Epoch 97 | Loss: 6.931e-01\n",
      "Epoch 98 | Loss: 6.931e-01\n",
      "Epoch 99 | Loss: 6.931e-01\n",
      "Epoch 100 | Loss: 6.931e-01\n",
      "Epoch 101 | Loss: 6.931e-01\n",
      "Epoch 102 | Loss: 6.931e-01\n",
      "Epoch 103 | Loss: 6.931e-01\n",
      "Epoch 104 | Loss: 6.931e-01\n",
      "Epoch 105 | Loss: 6.931e-01\n",
      "Epoch 106 | Loss: 6.931e-01\n",
      "Epoch 107 | Loss: 6.931e-01\n",
      "Epoch 108 | Loss: 6.931e-01\n",
      "Epoch 109 | Loss: 6.931e-01\n",
      "Epoch 110 | Loss: 6.931e-01\n",
      "Epoch 111 | Loss: 6.931e-01\n",
      "Epoch 112 | Loss: 6.931e-01\n",
      "Epoch 113 | Loss: 6.931e-01\n",
      "Epoch 114 | Loss: 6.931e-01\n",
      "Epoch 115 | Loss: 6.931e-01\n",
      "Epoch 116 | Loss: 6.931e-01\n",
      "Epoch 117 | Loss: 6.931e-01\n",
      "Epoch 118 | Loss: 6.931e-01\n",
      "Epoch 119 | Loss: 6.931e-01\n",
      "Epoch 120 | Loss: 6.931e-01\n",
      "Epoch 121 | Loss: 6.931e-01\n",
      "Epoch 122 | Loss: 6.931e-01\n",
      "Epoch 123 | Loss: 6.931e-01\n",
      "Epoch 124 | Loss: 6.931e-01\n",
      "Epoch 125 | Loss: 6.931e-01\n",
      "Epoch 126 | Loss: 6.931e-01\n",
      "Epoch 127 | Loss: 6.931e-01\n",
      "Epoch 128 | Loss: 6.931e-01\n",
      "Epoch 129 | Loss: 6.931e-01\n",
      "Epoch 130 | Loss: 6.931e-01\n",
      "Epoch 131 | Loss: 6.931e-01\n",
      "Epoch 132 | Loss: 6.931e-01\n",
      "Epoch 133 | Loss: 6.931e-01\n",
      "Epoch 134 | Loss: 6.931e-01\n",
      "Epoch 135 | Loss: 6.931e-01\n",
      "Epoch 136 | Loss: 6.931e-01\n",
      "Epoch 137 | Loss: 6.931e-01\n",
      "Epoch 138 | Loss: 6.931e-01\n",
      "Epoch 139 | Loss: 6.931e-01\n",
      "Epoch 140 | Loss: 6.931e-01\n",
      "Epoch 141 | Loss: 6.931e-01\n",
      "Epoch 142 | Loss: 6.931e-01\n",
      "Epoch 143 | Loss: 6.931e-01\n",
      "Epoch 144 | Loss: 6.931e-01\n",
      "Epoch 145 | Loss: 6.931e-01\n",
      "Epoch 146 | Loss: 6.931e-01\n",
      "Epoch 147 | Loss: 6.931e-01\n",
      "Epoch 148 | Loss: 6.931e-01\n",
      "Epoch 149 | Loss: 6.931e-01\n",
      "Epoch 150 | Loss: 6.931e-01\n",
      "Epoch 151 | Loss: 6.931e-01\n",
      "Epoch 152 | Loss: 6.931e-01\n",
      "Epoch 153 | Loss: 6.931e-01\n",
      "Epoch 154 | Loss: 6.931e-01\n",
      "Epoch 155 | Loss: 6.931e-01\n",
      "Epoch 156 | Loss: 6.931e-01\n",
      "Epoch 157 | Loss: 6.931e-01\n",
      "Epoch 158 | Loss: 6.931e-01\n",
      "Epoch 159 | Loss: 6.931e-01\n",
      "Epoch 160 | Loss: 6.931e-01\n",
      "Epoch 161 | Loss: 6.931e-01\n",
      "Epoch 162 | Loss: 6.931e-01\n",
      "Epoch 163 | Loss: 6.931e-01\n",
      "Epoch 164 | Loss: 6.931e-01\n",
      "Epoch 165 | Loss: 6.931e-01\n",
      "Epoch 166 | Loss: 6.931e-01\n",
      "Epoch 167 | Loss: 6.931e-01\n",
      "Epoch 168 | Loss: 6.931e-01\n",
      "Epoch 169 | Loss: 6.931e-01\n",
      "Epoch 170 | Loss: 6.931e-01\n",
      "Epoch 171 | Loss: 6.931e-01\n",
      "Epoch 172 | Loss: 6.931e-01\n",
      "Epoch 173 | Loss: 6.931e-01\n",
      "Epoch 174 | Loss: 6.931e-01\n",
      "Epoch 175 | Loss: 6.931e-01\n",
      "Epoch 176 | Loss: 6.931e-01\n",
      "Epoch 177 | Loss: 6.931e-01\n",
      "Epoch 178 | Loss: 6.931e-01\n",
      "Epoch 179 | Loss: 6.931e-01\n",
      "Epoch 180 | Loss: 6.931e-01\n",
      "Epoch 181 | Loss: 6.931e-01\n",
      "Epoch 182 | Loss: 6.931e-01\n",
      "Epoch 183 | Loss: 6.931e-01\n",
      "Epoch 184 | Loss: 6.931e-01\n",
      "Epoch 185 | Loss: 6.931e-01\n",
      "Epoch 186 | Loss: 6.931e-01\n",
      "Epoch 187 | Loss: 6.931e-01\n",
      "Epoch 188 | Loss: 6.931e-01\n",
      "Epoch 189 | Loss: 6.931e-01\n",
      "Epoch 190 | Loss: 6.931e-01\n",
      "Epoch 191 | Loss: 6.931e-01\n",
      "Epoch 192 | Loss: 6.931e-01\n",
      "Epoch 193 | Loss: 6.931e-01\n",
      "Epoch 194 | Loss: 6.931e-01\n",
      "Epoch 195 | Loss: 6.931e-01\n",
      "Epoch 196 | Loss: 6.931e-01\n",
      "Epoch 197 | Loss: 6.931e-01\n",
      "Epoch 198 | Loss: 6.931e-01\n",
      "Epoch 199 | Loss: 6.931e-01\n"
     ]
    }
   ],
   "source": [
    "all_logits = []\n",
    "for epoch in range(numEpochs):\n",
    "    logits = net(G, inputs)\n",
    "    # we save the logits for visualization later\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch %d | Loss: %6.3e' % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True IPO:  250\n",
      "False IPO:  84\n",
      "True Non-IPO:  916\n",
      "False Non-IPO:  750\n"
     ]
    }
   ],
   "source": [
    "predictions = list(all_logits[numEpochs-1])\n",
    "predictIPO = []\n",
    "predictNonIPO = []\n",
    "\n",
    "a=0\n",
    "for company in predictions:\n",
    "    if company[1] >= company[0]:\n",
    "        predictIPO.append(numToComp[a])\n",
    "    else:\n",
    "        predictNonIPO.append(numToComp[a])\n",
    "    a += 1\n",
    "\n",
    "trueIPO = 0\n",
    "falseIPO = 0\n",
    "trueNonIPO = 0\n",
    "falseNonIPO = 0\n",
    "\n",
    "\n",
    "for prediction in predictIPO:\n",
    "    if prediction in ipoed:\n",
    "        trueIPO += 1\n",
    "    else:\n",
    "        falseIPO += 1\n",
    "\n",
    "print(\"True IPO: \", trueIPO)\n",
    "print(\"False IPO: \", falseIPO)\n",
    "\n",
    "for prediction in predictNonIPO:\n",
    "    if prediction in ipoed:\n",
    "        falseNonIPO += 1        \n",
    "    else:\n",
    "        trueNonIPO += 1\n",
    "print(\"True Non-IPO: \", trueNonIPO)\n",
    "print(\"False Non-IPO: \", falseNonIPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.583\n"
     ]
    }
   ],
   "source": [
    "accuracy = (trueNonIPO+trueIPO)/(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "<p><img alt=\"Picture of Parker Erickson\" height=\"150px\" src=\"https://avatars1.githubusercontent.com/u/9616171?s=460&v=4\" align=\"right\" hspace=\"20px\" vspace=\"20px\"></p>\n",
    "\n",
    "Demo/tutorial written by Parker Erickson, a student at the University of Minnesota pursuing a B.S. in Computer Science. His interests include graph databases, machine learning, travelling, playing the saxophone, and watching Minnesota Twins baseball. Feel free to reach out! Find him on:\n",
    "\n",
    "* LinkedIn: [https://www.linkedin.com/in/parker-erickson/](https://www.linkedin.com/in/parker-erickson/)\n",
    "* GitHub: [https://github.com/parkererickson](https://github.com/parkererickson)\n",
    "* Medium: [https://medium.com/@parker.erickson](https://medium.com/@parker.erickson)\n",
    "* Email: [parker.erickson30@gmail.com](parker.erickson30@gmail.com)\n",
    "----\n",
    "GCN Resources:\n",
    "* DGL Documentation: [https://docs.dgl.ai/](https://docs.dgl.ai/)\n",
    "* GCN paper by Kipf and Welling [https://arxiv.org/abs/1609.02907](https://arxiv.org/abs/1609.02907)\n",
    "* R-GCN paper: [https://arxiv.org/abs/1703.06103](https://arxiv.org/abs/1703.06103)\n",
    "---- \n",
    "Notebook adapted from: [https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html](https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit5e4270a542e54d6788076e0986af2669"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
