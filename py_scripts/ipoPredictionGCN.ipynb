{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPO Prediction of Using Graph Convolutional Neural Networks\n",
    "## By Parker Erickson\n",
    "\n",
    "In this notebook, we will install and run queries on a TigerGraph database to collect data from their Crunchbase Knowledge Graph demo and then pipe this data into a Graph Convolutional Neural Network (GCN) to predict whether or not a company will IPO. The performance of the GCN is not astounding, but we will explore why this is due to the very nature of the dataset and some of the simplifications I make. Other models may fair better, although these avenues haven't been explored yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TigerGraph Setup\n",
    "\n",
    "We will be installing the queries found in ../db_scripts onto the TigerGraph database. This will create a REST endpoint that the package pyTigerGraph will request from in order to grab the data for the GCN. If you haven't already done so, create a free TigerGraph cloud instance of the CrunchBase knowledge graph demo. Then, configure your gradle-local.properties file and get a SSL certificate from the server following the directions found [here](https://medium.com/@jon.herke/getting-started-with-giraffle-on-tigergraph-cloud-970ead739943). Then, we will be all set to use gradle and Giraffle to install the necessary queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n",
    "\n",
    "!gradle tasks --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gradle createCompanyLinks --console=plain\n",
    "!gradle installCompanyLinks --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gradle createGetAllIpo --console=plain\n",
    "!gradle installGetAllIpo --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gradle createGetAllCompanies --console=plain\n",
    "!gradle installGetAllCompanies --console=plain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTigerGraph as tg \n",
    "import cfg\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyTigerGraph as tg\n",
    "import dgl\n",
    "import networkx as nx\n",
    "from heapq import nlargest, nsmallest\n",
    "\n",
    "from gcn import GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Connection to Database and Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting API token from Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.token = tg.TigerGraphConnection(host=\"https://crunchml1.i.tgcloud.io\", graphname=\"CrunchBasePre_2013\").getToken(cfg.secret, \"1000000\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = tg.TigerGraphConnection(host=\"https://crunchml1.i.tgcloud.io\", graphname=\"CrunchBasePre_2013\", password=cfg.password, apiToken=cfg.token)\n",
    "conn.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Edges Between Companies\n",
    "\n",
    "The cell below runs the query companyLinks, and then formats each edge into a tuple (src, destination). Unfortunately, due to both memory constraints as well as the imbalanced nature of the dataset, we will not use all of the edges in the graph, and instead sample nodes and then search this list for edges between the nodes.\n",
    "\n",
    "#### **Assumption Alert:** We oversimplify the graph here. The query returns pairs of companies that have something in common. This hurts accuracy (a lot). Where TigerGraph comes in is the ease of data extraction, as there are no JOIN operations to create these links between companies.\n",
    "* Note: It is possible to create a GCN that has multiple types of verticies, (known as a Relational Graph Convolutional Notebook) but it is more complex. A good way to get started is to simplify until you only have relations between the same type of thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "edges = [(thing[\"src\"], thing[\"dest\"]) for thing in conn.runInstalledQuery(\"companyLinks\", {}, sizeLimit=512000000, timeout=320000)[0][\"@@tupleRecords\"]]\n",
    "print(edges[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the List of IPOed Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"Getting IPOed List\")\n",
    "ipoed = list(set([thing[\"src\"] for thing in conn.runInstalledQuery(\"getAllIpo\", {}, sizeLimit=512000000, timeout=320000)[0][\"@@tupleRecords\"]]) - set(['']))\n",
    "print(\"Getting Non IPOed List\")\n",
    "nonipo = list(set([thing[\"src\"] for thing in conn.runInstalledQuery(\"getAllCompanies\", {}, sizeLimit=512000000, timeout=320000)[0][\"@@tupleRecords\"]]) - set(ipoed) - set(['']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Over-Sampled IPO Graph\n",
    "\n",
    "The code blocks below sample a number of nodes from each the IPOed list and the non-IPO list and determines what edges there are between the sampled nodes. Unfortunately, due to the large number of nodes in the complete graph, the number of edges in the sampled graph is quite small. This lack of edges contributes to the mediocre and highly variant performance of the following GCN. Other graph machine learning approaches such as node2vec might fair better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "numberofnodes = 1000\n",
    "\n",
    "print(\"Number of IPOs: \", len(ipoed))\n",
    "ipoedsample = random.choices(ipoed, k=numberofnodes)\n",
    "noniposample = random.choices(nonipo, k=numberofnodes)\n",
    "print(\"Total number of nodes: \", len(noniposample)+len(ipoedsample))\n",
    "\n",
    "allNodes = noniposample+ipoedsample\n",
    "\n",
    "print(len(allNodes))\n",
    "\n",
    "\n",
    "finalEdges = []\n",
    "\n",
    "print(\"Computing edges\")\n",
    "for edge in edges:\n",
    "    if edge[0] in allNodes and edge[1] in allNodes:\n",
    "            finalEdges.append(edge)\n",
    "\n",
    "print(len(finalEdges))\n",
    "print(finalEdges[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compToNum = {} # translation dictionary for company name to number (for dgl)\n",
    "numToComp = {} # translation dictionary for number to company name\n",
    "\n",
    "numericalNodes = []\n",
    "\n",
    "for i in range(0, len(allNodes)):\n",
    "    compToNum[allNodes[i]] = i\n",
    "    numericalNodes.append(i)\n",
    "    numToComp[i] = allNodes[i]\n",
    "\n",
    "def createEdgeList(result): # returns tuple of number version of edge\n",
    "    fromKey = compToNum[result[0]]\n",
    "    toKey = compToNum[result[1]]\n",
    "    return (fromKey, toKey)\n",
    "\n",
    "edges = [createEdgeList(thing) for thing in finalEdges]\n",
    "print(\"Number of Edges: \", len(edges))\n",
    "print(edges[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_nodes_from(numericalNodes)\n",
    "g.add_edges_from(edges)\n",
    "\n",
    "\n",
    "G = dgl.DGLGraph(g) # Convert networkx graph to a graph that DGL can work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding of Node Features\n",
    "We one-hot encode the features of the verticies in the graph. Feature assignment can be done a multitude of different ways, this is just the fastest and easiest.\n",
    "\n",
    "If you had a graph of documents for example, you could run doc2vec on those documents to create a feature vector and create the feature matrix by concatenating those together.\n",
    "\n",
    "Another possiblity is that you have a graph of songs, artists, albums, etc. and you could use tempo, max volume, minimum volume, length, and other numerical descriptions of the song to create the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.ndata[\"feat\"] = torch.eye(G.number_of_nodes())\n",
    "\n",
    "print(G.nodes[2].data['feat'])\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Neural Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 100\n",
    "learningRate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Neural Network and Labelling Relevant Verticies\n",
    "\n",
    "Here, we create the GCN. A two-layered GCN appears to work better than deeper networks, and this is further corroborated by the fact [this](https://arxiv.org/abs/1609.02907) paper only used a two-layered one. We also label the wanted and unwanted verticies and setup the optimizer. Since the GCN is a semi-supervised algorithm, we do not label all of the nodes to their correct classes before training - only two are needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compIPO = 0\n",
    "compNonIPO = 0\n",
    "i = 0\n",
    "while((not(compIPO) or not(compNonIPO)) and (i<G.number_of_nodes())):\n",
    "    if numToComp[i] in ipoed:\n",
    "        compIPO = i\n",
    "    else:\n",
    "        compNonIPO = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GCN(G.number_of_nodes(), 32, 2) #Two layer GCN\n",
    "inputs = G.ndata[\"feat\"]\n",
    "labeled_nodes = torch.tensor([compNonIPO, compIPO])  # only the liked movies and the disliked movies are labelled\n",
    "labels = torch.tensor([0, 1])  # their labels are different\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GCN\n",
    "\n",
    "Below is the training loop that actually trains the GCN. Unlike many traditional deep learning architectures, GCNs don't always need that much training or as large of data sets due to their exploitation of the *structure* of the data, as opposed to only the features of the data.\n",
    "* Note: due to the randomized initial values of the weights in the neural network and our lack of a very well-connected graph, sometimes models don't work very well, or their loss gets stuck at a relatively large number. If that happens, just stop and restart the training process (also rerun the cell above to reset the weights) and hope for better luck! Alternatively, you can run more epochs in hopes of eventually getting out of the rut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logits = []\n",
    "for epoch in range(numEpochs):\n",
    "    logits = net(G, inputs)\n",
    "    # we save the logits for visualization later\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch %d | Loss: %6.3e' % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(all_logits[numEpochs-1])\n",
    "predictIPO = []\n",
    "predictNonIPO = []\n",
    "\n",
    "a=0\n",
    "for company in predictions:\n",
    "    if company[1] >= company[0]:\n",
    "        predictIPO.append(numToComp[a])\n",
    "    else:\n",
    "        predictNonIPO.append(numToComp[a])\n",
    "    a += 1\n",
    "\n",
    "trueIPO = 0\n",
    "falseIPO = 0\n",
    "trueNonIPO = 0\n",
    "falseNonIPO = 0\n",
    "\n",
    "\n",
    "for prediction in predictIPO:\n",
    "    if prediction in ipoed:\n",
    "        trueIPO += 1\n",
    "    else:\n",
    "        falseIPO += 1\n",
    "\n",
    "print(\"True IPO: \", trueIPO)\n",
    "print(\"False IPO: \", falseIPO)\n",
    "\n",
    "for prediction in predictNonIPO:\n",
    "    if prediction in ipoed:\n",
    "        falseNonIPO += 1        \n",
    "    else:\n",
    "        trueNonIPO += 1\n",
    "print(\"True Non-IPO: \", trueNonIPO)\n",
    "print(\"False Non-IPO: \", falseNonIPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (trueNonIPO+trueIPO)/(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "<p><img alt=\"Picture of Parker Erickson\" height=\"150px\" src=\"https://avatars1.githubusercontent.com/u/9616171?s=460&v=4\" align=\"right\" hspace=\"20px\" vspace=\"20px\"></p>\n",
    "\n",
    "Demo/tutorial written by Parker Erickson, a student at the University of Minnesota pursuing a B.S. in Computer Science. His interests include graph databases, machine learning, traveling, playing the saxophone, and watching Minnesota Twins baseball. Feel free to reach out! Find him on:\n",
    "\n",
    "* LinkedIn: [https://www.linkedin.com/in/parker-erickson/](https://www.linkedin.com/in/parker-erickson/)\n",
    "* GitHub: [https://github.com/parkererickson](https://github.com/parkererickson)\n",
    "* Medium: [https://medium.com/@parker.erickson](https://medium.com/@parker.erickson)\n",
    "* Email: [parker.erickson30@gmail.com](parker.erickson30@gmail.com)\n",
    "----\n",
    "GCN Resources:\n",
    "* DGL Documentation: [https://docs.dgl.ai/](https://docs.dgl.ai/)\n",
    "* GCN paper by Kipf and Welling [https://arxiv.org/abs/1609.02907](https://arxiv.org/abs/1609.02907)\n",
    "* R-GCN paper: [https://arxiv.org/abs/1703.06103](https://arxiv.org/abs/1703.06103)\n",
    "---- \n",
    "Notebook adapted from: [https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html](https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit5e4270a542e54d6788076e0986af2669"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}