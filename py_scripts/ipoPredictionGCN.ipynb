{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPO Prediction of Using Graph Convolutional Neural Networks\n",
    "## By Parker Erickson\n",
    "\n",
    "In this notebook, we will install and run queries on a TigerGraph database to collect data from their Crunchbase Knowledge Graph demo and then pipe this data into a Graph Convolutional Neural Network (GCN) to predict whether or not a company will IPO. The performance of the GCN is not astounding, but we will explore why this is due to the very nature of the dataset and some of the simplifications I make. Other models may fair better, although these avenues haven't been explored yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TigerGraph Setup\n",
    "\n",
    "We will be installing the queries found in ../db_scripts onto the TigerGraph database. This will create a REST endpoint that the package pyTigerGraph will request from in order to grab the data for the GCN. If you haven't already done so, create a free TigerGraph cloud instance of the CrunchBase knowledge graph demo. Then, configure your gradle-local.properties file and get a SSL certificate from the server following the directions found [here](https://medium.com/@jon.herke/getting-started-with-giraffle-on-tigergraph-cloud-970ead739943). Then, we will be all set to use gradle and Giraffle to install the necessary queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/parker/crunchbaseGraph\n\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :tasks\n\n------------------------------------------------------------\nTasks runnable from root project\n------------------------------------------------------------\n\nBuild tasks\n-----------\ngsqlCopySources - Copy gsql scripts from input directory to build directory prior to execution.\n\nBuild Setup tasks\n-----------------\ninit - Initializes a new Gradle build.\nwrapper - Generates Gradle wrapper files.\n\nGSQL Interactive tasks\n----------------------\ngsqlShell - Run an interactive gsql shell session\n\nGSQL Project Wizard tasks\n-------------------------\ngsqlNewProject - Create scaffolding for new project\n\nHelp tasks\n----------\nbuildEnvironment - Displays all buildscript dependencies declared in root project 'crunchbaseGraph'.\ncomponents - Displays the components produced by root project 'crunchbaseGraph'. [incubating]\ndependencies - Displays all dependencies declared in root project 'crunchbaseGraph'.\ndependencyInsight - Displays the insight into a specific dependency in root project 'crunchbaseGraph'.\ndependentComponents - Displays the dependent components of components in root project 'crunchbaseGraph'. [incubating]\nhelp - Displays a help message.\nkotlinDslAccessorsReport - Prints the Kotlin code for accessing the currently available project extensions and conventions.\nmodel - Displays the configuration model of root project 'crunchbaseGraph'. [incubating]\noutgoingVariants - Displays the outgoing variants of root project 'crunchbaseGraph'.\nprojects - Displays the sub-projects of root project 'crunchbaseGraph'.\nproperties - Displays the properties of root project 'crunchbaseGraph'.\ntasks - Displays the tasks runnable from root project 'crunchbaseGraph'.\n\nTigergraph Authentication tasks\n-------------------------------\ngsqlDeleteToken - Uses Tigergraph's REST end point to delete an OAUTH token\ngsqlToken - Uses Tigergraph's REST endpoint to obtain an OAUTH token\n\nTigergraph Queries tasks\n------------------------\ncreateCompanyLinks - Creates the companyLinks query\ncreateGetAllCompanies - Creates the getAllCompanies query\ncreateGetAllIpo - Creates the getAllIpo query\ninstallCompanyLinks - Installs the companyLinks query\ninstallGetAllCompanies - Installs the getAllCompanies query\ninstallGetAllIpo - Installs the getAllIpo query\n\nTo see all tasks and more detail, run gradle tasks --all\n\nTo see more detail about a task, run gradle help --task <task>\n\nBUILD SUCCESSFUL in 1s\n1 actionable task: 1 executed\n\u001b[m"
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "!gradle tasks --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :createCompanyLinks\nSupported Versions ( v2_6_0 v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_6_0\nConnecting to crunchml1.i.tgcloud.io\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nThe query companyLinks has been added!\n\nBUILD SUCCESSFUL in 4s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :installCompanyLinks\nSupported Versions ( v2_6_0 v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_6_0\nConnecting to crunchml1.i.tgcloud.io\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nStart installing queries, about 1 minute ...\ncompanyLinks query: curl -X GET 'https://127.0.0.1:9000/query/CrunchBasePre_2013/companyLinks'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n\n[=================================================================] 100% (1/1) \n\nBUILD SUCCESSFUL in 1m 2s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m"
    }
   ],
   "source": [
    "!gradle createCompanyLinks --console=plain\n",
    "!gradle installCompanyLinks --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :createGetAllIpo\nSupported Versions ( v2_6_0 v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_6_0\nConnecting to crunchml1.i.tgcloud.io\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nThe query getAllIpo has been added!\n\nBUILD SUCCESSFUL in 3s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :installGetAllIpo\nSupported Versions ( v2_6_0 v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_6_0\nConnecting to crunchml1.i.tgcloud.io\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nStart installing queries, about 1 minute ...\ngetAllIpo query: curl -X GET 'https://127.0.0.1:9000/query/CrunchBasePre_2013/getAllIpo'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n\n[=================================================================] 100% (1/1) \n\nBUILD SUCCESSFUL in 32s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m"
    }
   ],
   "source": [
    "!gradle createGetAllIpo --console=plain\n",
    "!gradle installGetAllIpo --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :createGetAllCompanies\nSupported Versions ( v2_6_0 v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_6_0\nConnecting to crunchml1.i.tgcloud.io\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nThe query getAllCompanies has been added!\n\nBUILD SUCCESSFUL in 2s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :installGetAllCompanies\nSupported Versions ( v2_6_0 v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_6_0\nConnecting to crunchml1.i.tgcloud.io\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nStart installing queries, about 1 minute ...\ngetAllCompanies query: curl -X GET 'https://127.0.0.1:9000/query/CrunchBasePre_2013/getAllCompanies'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n\n[=================================================================] 100% (1/1) \n\nBUILD SUCCESSFUL in 30s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m"
    }
   ],
   "source": [
    "!gradle createGetAllCompanies --console=plain\n",
    "!gradle installGetAllCompanies --console=plain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTigerGraph as tg \n",
    "import cfg\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyTigerGraph as tg\n",
    "import dgl\n",
    "import networkx as nx\n",
    "from heapq import nlargest, nsmallest\n",
    "\n",
    "from gcn import GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Connection to Database and Getting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting API token from Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.token = tg.TigerGraphConnection(host=\"https://crunchml1.i.tgcloud.io\", graphname=\"CrunchBasePre_2013\").getToken(cfg.secret, \"1000000\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = tg.TigerGraphConnection(host=\"https://crunchml1.i.tgcloud.io\", graphname=\"CrunchBasePre_2013\", password=cfg.password, apiToken=cfg.token)\n",
    "conn.debug=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Edges Between Companies\n",
    "\n",
    "The cell below runs the query companyLinks, and then formats each edge into a tuple (src, destination). Unfortunately, due to both memory constraints as well as the imbalanced nature of the dataset, we will not use all of the edges in the graph, and instead sample nodes and then search this list for edges between the nodes.\n",
    "\n",
    "#### **Assumption Alert:** We oversimplify the graph here. The query returns pairs of companies that have something in common. This hurts accuracy (a lot). Where TigerGraph comes in is the ease of data extraction, as there are no JOIN operations to create these links between companies.\n",
    "* Note: It is possible to create a GCN that has multiple types of verticies, (known as a Relational Graph Convolutional Notebook) but it is more complex. A good way to get started is to simplify until you only have relations between the same type of thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('shutlshutl', 'acnielsen'), ('dailymotiondailymotion', 'acnielsen'), ('qxl ricardo', 'acnielsen')]\n"
    }
   ],
   "source": [
    "edges = [(thing[\"src\"], thing[\"dest\"]) for thing in conn.runInstalledQuery(\"companyLinks\", {}, sizeLimit=512000000, timeout=320000)[0][\"@@tupleRecords\"]]\n",
    "print(edges[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the List of IPOed Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Getting IPOed List\nGetting Non IPOed List\n"
    }
   ],
   "source": [
    "print(\"Getting IPOed List\")\n",
    "ipoed = list(set([thing[\"src\"] for thing in conn.runInstalledQuery(\"getAllIpo\", {}, sizeLimit=512000000, timeout=320000)[0][\"@@tupleRecords\"]]) - set(['']))\n",
    "print(\"Getting Non IPOed List\")\n",
    "nonipo = list(set([thing[\"src\"] for thing in conn.runInstalledQuery(\"getAllCompanies\", {}, sizeLimit=512000000, timeout=320000)[0][\"@@tupleRecords\"]]) - set(ipoed) - set(['']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Over-Sampled IPO Graph\n",
    "\n",
    "The code blocks below sample a number of nodes from each the IPOed list and the non-IPO list and determines what edges there are between the sampled nodes. Unfortunately, due to the large number of nodes in the complete graph, the number of edges in the sampled graph is quite small. This lack of edges contributes to the mediocre and highly variant performance of the following GCN. Other graph machine learning approaches such as node2vec might fair better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of IPOs:  1238\nComputing edges\n243767\n[('chairish', 'opsware'), ('columbia universitycolumbia university', 'opsware'), ('groupize', 'opsware')]\n"
    }
   ],
   "source": [
    "numberofnodes = 1000\n",
    "\n",
    "print(\"Number of IPOs: \", len(ipoed))\n",
    "ipoedsample = random.choices(ipoed, k=numberofnodes)\n",
    "noniposample = random.choices(nonipo, k=numberofnodes)\n",
    "print(\"Total number of nodes: \", len(noniposample)+len(ipoedsample))\n",
    "\n",
    "allNodes = noniposample+ipoedsample\n",
    "\n",
    "print(len(allNodes))\n",
    "\n",
    "\n",
    "finalEdges = []\n",
    "\n",
    "print(\"Computing edges\")\n",
    "for edge in edges:\n",
    "    if edge[0] in allNodes and edge[1] in allNodes:\n",
    "            finalEdges.append(edge)\n",
    "\n",
    "print(len(finalEdges))\n",
    "print(finalEdges[:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of Edges:  243767\n[(0, 1), (2, 1), (3, 1), (4, 1), (5, 1)]\n"
    }
   ],
   "source": [
    "compToNum = {} # translation dictionary for company name to number (for dgl)\n",
    "numToComp = {} # translation dictionary for number to company name\n",
    "\n",
    "numericalNodes = []\n",
    "'''\n",
    "for i in range(0, len(allNodes)):\n",
    "    compToNum[allNodes[i]] = i\n",
    "    numericalNodes.append(i)\n",
    "    numToComp[i] = allNodes[i]\n",
    "'''\n",
    "\n",
    "i = 0\n",
    "\n",
    "def createEdgeList(result): # returns tuple of number version of edge\n",
    "    global i\n",
    "    if result[0] in compToNum.keys():\n",
    "        fromKey = compToNum[result[0]]\n",
    "    else:\n",
    "        compToNum[result[0]] = i\n",
    "        numToComp[i] = result[0]\n",
    "        fromKey = i\n",
    "        i += 1\n",
    "    if result[1] in compToNum.keys():\n",
    "        toKey = compToNum[result[1]]\n",
    "    else:\n",
    "        compToNum[result[1]] = i\n",
    "        numToComp[i] = result[1]\n",
    "        toKey = i\n",
    "        i += 1      \n",
    "    return (fromKey, toKey)\n",
    "\n",
    "edges = [createEdgeList(thing) for thing in finalEdges]\n",
    "print(\"Number of Edges: \", len(edges))\n",
    "print(edges[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_nodes_from(numericalNodes)\n",
    "g.add_edges_from(edges)\n",
    "\n",
    "\n",
    "G = dgl.DGLGraph(g) # Convert networkx graph to a graph that DGL can work on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "42440"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding of Node Features\n",
    "We one-hot encode the features of the verticies in the graph. Feature assignment can be done a multitude of different ways, this is just the fastest and easiest.\n",
    "\n",
    "If you had a graph of documents for example, you could run doc2vec on those documents to create a feature vector and create the feature matrix by concatenating those together.\n",
    "\n",
    "Another possiblity is that you have a graph of songs, artists, albums, etc. and you could use tempo, max volume, minimum volume, length, and other numerical descriptions of the song to create the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0., 0., 1.,  ..., 0., 0., 0.]])\n"
    }
   ],
   "source": [
    "G.ndata[\"feat\"] = torch.eye(G.number_of_nodes())\n",
    "\n",
    "print(G.nodes[2].data['feat'])\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Neural Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 100\n",
    "learningRate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Neural Network and Labelling Relevant Verticies\n",
    "\n",
    "Here, we create the GCN. A two-layered GCN appears to work better than deeper networks, and this is further corroborated by the fact [this](https://arxiv.org/abs/1609.02907) paper only used a two-layered one. We also label the wanted and unwanted verticies and setup the optimizer. Since the GCN is a semi-supervised algorithm, we do not label all of the nodes to their correct classes before training - only two are needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "compIPO = 0\n",
    "compNonIPO = 0\n",
    "i = 0\n",
    "while((not(compIPO) or not(compNonIPO)) and (i<G.number_of_nodes())):\n",
    "    if numToComp[i] in ipoed:\n",
    "        compIPO = i\n",
    "    else:\n",
    "        compNonIPO = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GCN(G.number_of_nodes(), 32, 2) #Two layer GCN\n",
    "inputs = G.ndata[\"feat\"]\n",
    "labeled_nodes = torch.tensor([compNonIPO, compIPO])  # only the liked movies and the disliked movies are labelled\n",
    "labels = torch.tensor([0, 1])  # their labels are different\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GCN\n",
    "\n",
    "Below is the training loop that actually trains the GCN. Unlike many traditional deep learning architectures, GCNs don't always need that much training or as large of data sets due to their exploitation of the *structure* of the data, as opposed to only the features of the data.\n",
    "* Note: due to the randomized initial values of the weights in the neural network and our lack of a very well-connected graph, sometimes models don't work very well, or their loss gets stuck at a relatively large number. If that happens, just stop and restart the training process (also rerun the cell above to reset the weights) and hope for better luck! Alternatively, you can run more epochs in hopes of eventually getting out of the rut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 60152588640 bytes. Error code 12 (Cannot allocate memory)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-91081cf659da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mall_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumEpochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# we save the logits for visualization later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/crunchbaseGraph/py_scripts/gcn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, inputs)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/crunchbaseGraph/py_scripts/gcn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, inputs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# trigger message passing on all edges\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;31m# trigger aggregation at all nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/graph.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, edges, message_func)\u001b[0m\n\u001b[1;32m   2780\u001b[0m             scheduler.schedule_send(graph=AdaptedDGLGraph(self), u=u, v=v, eid=eid,\n\u001b[1;32m   2781\u001b[0m                                     message_func=message_func)\n\u001b[0;32m-> 2782\u001b[0;31m             \u001b[0mRuntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     def recv(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/runtime.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(prog)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mexe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m# prog.pprint_exe(exe)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mexe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/ir/executor.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0medge_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfdedge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mdst_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfddst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mudf_ret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mudf_ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/runtime/scheduler.py\u001b[0m in \u001b[0;36m_mfunc_wrapper\u001b[0;34m(src_data, edge_data, dst_data)\u001b[0m\n\u001b[1;32m    970\u001b[0m                            \u001b[0msrc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m                            canonical_etype=canonical_etype)\n\u001b[0;32m--> 972\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mebatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0m_mfunc_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFUNC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mfunc_wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEDGE_UDF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_mfunc_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdedge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfddst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/crunchbaseGraph/py_scripts/gcn.py\u001b[0m in \u001b[0;36mgcn_message\u001b[0;34m(edges)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# The argument is a batch of edges.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# This computes a (batch of) message called 'msg' using the source node's feature 'h'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'msg'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgcn_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/utils.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/frame.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    653\u001b[0m         \"\"\"\n\u001b[1;32m    654\u001b[0m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLazyDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0muser_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtousertensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mgather_row\u001b[0;34m(data, row_index)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgather_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mslice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 60152588640 bytes. Error code 12 (Cannot allocate memory)\n"
     ]
    }
   ],
   "source": [
    "all_logits = []\n",
    "for epoch in range(numEpochs):\n",
    "    logits = net(G, inputs)\n",
    "    # we save the logits for visualization later\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch %d | Loss: %6.3e' % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True IPO:  525\nFalse IPO:  363\nTrue Non-IPO:  241\nFalse Non-IPO:  84\n"
    }
   ],
   "source": [
    "predictions = list(all_logits[numEpochs-1])\n",
    "predictIPO = []\n",
    "predictNonIPO = []\n",
    "\n",
    "a=0\n",
    "for company in predictions:\n",
    "    if company[1] >= company[0]:\n",
    "        predictIPO.append(numToComp[a])\n",
    "    else:\n",
    "        predictNonIPO.append(numToComp[a])\n",
    "    a += 1\n",
    "\n",
    "trueIPO = 0\n",
    "falseIPO = 0\n",
    "trueNonIPO = 0\n",
    "falseNonIPO = 0\n",
    "\n",
    "\n",
    "for prediction in predictIPO:\n",
    "    if prediction in ipoed:\n",
    "        trueIPO += 1\n",
    "    else:\n",
    "        falseIPO += 1\n",
    "\n",
    "print(\"True IPO: \", trueIPO)\n",
    "print(\"False IPO: \", falseIPO)\n",
    "\n",
    "for prediction in predictNonIPO:\n",
    "    if prediction in ipoed:\n",
    "        falseNonIPO += 1        \n",
    "    else:\n",
    "        trueNonIPO += 1\n",
    "print(\"True Non-IPO: \", trueNonIPO)\n",
    "print(\"False Non-IPO: \", falseNonIPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.6314921681780709\n"
    }
   ],
   "source": [
    "accuracy = (trueNonIPO+trueIPO)/(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "<p><img alt=\"Picture of Parker Erickson\" height=\"150px\" src=\"https://avatars1.githubusercontent.com/u/9616171?s=460&v=4\" align=\"right\" hspace=\"20px\" vspace=\"20px\"></p>\n",
    "\n",
    "Demo/tutorial written by Parker Erickson, a student at the University of Minnesota pursuing a B.S. in Computer Science. His interests include graph databases, machine learning, traveling, playing the saxophone, and watching Minnesota Twins baseball. Feel free to reach out! Find him on:\n",
    "\n",
    "* LinkedIn: [https://www.linkedin.com/in/parker-erickson/](https://www.linkedin.com/in/parker-erickson/)\n",
    "* GitHub: [https://github.com/parkererickson](https://github.com/parkererickson)\n",
    "* Medium: [https://medium.com/@parker.erickson](https://medium.com/@parker.erickson)\n",
    "* Email: [parker.erickson30@gmail.com](parker.erickson30@gmail.com)\n",
    "----\n",
    "GCN Resources:\n",
    "* DGL Documentation: [https://docs.dgl.ai/](https://docs.dgl.ai/)\n",
    "* GCN paper by Kipf and Welling [https://arxiv.org/abs/1609.02907](https://arxiv.org/abs/1609.02907)\n",
    "* R-GCN paper: [https://arxiv.org/abs/1703.06103](https://arxiv.org/abs/1703.06103)\n",
    "---- \n",
    "Notebook adapted from: [https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html](https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit5e4270a542e54d6788076e0986af2669"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}