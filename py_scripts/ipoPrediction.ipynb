{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPO Prediction of Using Graph Convolutional Neural Networks\n",
    "## By Parker Erickson\n",
    "\n",
    "In this notebook, we will install and run queries on a TigerGraph database to collect data from their Crunchbase Knowledge Graph demo and then pipe this data into a Graph Convolutional Neural Network (GCN) to predict whether or not a company will IPO. The performance of the GCN is not astounding, but we will explore why this is due to the very nature of the dataset and some of the simplifications I make. Other models may fair better, although these avenues haven't been explored yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TigerGraph Setup\n",
    "\n",
    "We will be installing the queries found in ../db_scripts onto the TigerGraph database. This will create a REST endpoint that the package pyTigerGraph will request from in order to grab the data for the GCN. If you haven't already done so, create a free TigerGraph cloud instance of the CrunchBase knowledge graph demo. Then, configure your gradle-local.properties file and get a SSL certificate from the server following the directions found [here](https://medium.com/@jon.herke/getting-started-with-giraffle-on-tigergraph-cloud-970ead739943). Then, we will be all set to use gradle and Giraffle to install the necessary queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/home/parker/crunchbaseGraph\n\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :tasks\n\n------------------------------------------------------------\nTasks runnable from root project\n------------------------------------------------------------\n\nBuild tasks\n-----------\ngsqlCopySources - Copy gsql scripts from input directory to build directory prior to execution.\n\nBuild Setup tasks\n-----------------\ninit - Initializes a new Gradle build.\nwrapper - Generates Gradle wrapper files.\n\nGSQL Interactive tasks\n----------------------\ngsqlShell - Run an interactive gsql shell session\n\nGSQL Project Wizard tasks\n-------------------------\ngsqlNewProject - Create scaffolding for new project\n\nHelp tasks\n----------\nbuildEnvironment - Displays all buildscript dependencies declared in root project 'crunchbaseGraph'.\ncomponents - Displays the components produced by root project 'crunchbaseGraph'. [incubating]\ndependencies - Displays all dependencies declared in root project 'crunchbaseGraph'.\ndependencyInsight - Displays the insight into a specific dependency in root project 'crunchbaseGraph'.\ndependentComponents - Displays the dependent components of components in root project 'crunchbaseGraph'. [incubating]\nhelp - Displays a help message.\nkotlinDslAccessorsReport - Prints the Kotlin code for accessing the currently available project extensions and conventions.\nmodel - Displays the configuration model of root project 'crunchbaseGraph'. [incubating]\noutgoingVariants - Displays the outgoing variants of root project 'crunchbaseGraph'.\nprojects - Displays the sub-projects of root project 'crunchbaseGraph'.\nproperties - Displays the properties of root project 'crunchbaseGraph'.\ntasks - Displays the tasks runnable from root project 'crunchbaseGraph'.\n\nTigergraph Authentication tasks\n-------------------------------\ngsqlDeleteToken - Uses Tigergraph's REST end point to delete an OAUTH token\ngsqlToken - Uses Tigergraph's REST endpoint to obtain an OAUTH token\n\nTigergraph Queries tasks\n------------------------\ncreateCompanyLinks - Creates the companyLinks query\ncreateGetAllCompanies - Creates the getAllCompanies query\ncreateGetAllIpo - Creates the getAllIpo query\ninstallCompanyLinks - Installs the companyLinks query\ninstallGetAllCompanies - Installs the getAllCompanies query\ninstallGetAllIpo - Installs the getAllIpo query\n\nTo see all tasks and more detail, run gradle tasks --all\n\nTo see more detail about a task, run gradle help --task <task>\n\nBUILD SUCCESSFUL in 10s\n1 actionable task: 1 executed\n\u001b[m"
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "!gradle tasks --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources\n\n> Task :createCompanyLinks\nSupported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_5_2\nConnecting to crunchml.i.tgcloud.io:14240\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nThe query companyLinks has been added!\n\nBUILD SUCCESSFUL in 3s\n2 actionable tasks: 2 executed\n\u001b[m\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :installCompanyLinks\nSupported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_5_2\nConnecting to crunchml.i.tgcloud.io:14240\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nStart installing queries, about 1 minute ...\ncompanyLinks query: curl -X GET 'https://127.0.0.1:9000/query/CrunchBasePre_2013/companyLinks'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n\n[=================================================================] 100% (1/1) \n\nBUILD SUCCESSFUL in 46s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m"
    }
   ],
   "source": [
    "!gradle createCompanyLinks --console=plain\n",
    "!gradle installCompanyLinks --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :createGetAllIpo\nSupported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_5_2\nConnecting to crunchml.i.tgcloud.io:14240\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nThe query getAllIpo has been added!\n\nBUILD SUCCESSFUL in 3s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :installGetAllIpo\nSupported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_5_2\nConnecting to crunchml.i.tgcloud.io:14240\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nStart installing queries, about 1 minute ...\ngetAllIpo query: curl -X GET 'https://127.0.0.1:9000/query/CrunchBasePre_2013/getAllIpo'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n\n[=================================================================] 100% (1/1) \n\nBUILD SUCCESSFUL in 31s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m"
    }
   ],
   "source": [
    "!gradle createGetAllIpo --console=plain\n",
    "!gradle installGetAllIpo --console=plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :createGetAllCompanies\nSupported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_5_2\nConnecting to crunchml.i.tgcloud.io:14240\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nThe query getAllCompanies has been added!\n\nBUILD SUCCESSFUL in 3s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m\n> Configure project :\nGSQL Plugin successfully applied to crunchbaseGraph\n\n> Task :gsqlCopySources UP-TO-DATE\n\n> Task :installGetAllCompanies\nSupported Versions ( v2_5_2 v2_5_0 v2_4_1 v2_4_0 v2_3_2 )\nYou may use 'GSQL_CLIENT_VERSION=v? java ...' or \n    'java -DGSQL_CLIENT_VERSION=v? ...' to specify the version\n========================\nTrying version: v2_5_2\nConnecting to crunchml.i.tgcloud.io:14240\nIf there is any relative path, it is relative to tigergraph/dev/gdk/gsql\nUsing graph 'CrunchBasePre_2013'\nStart installing queries, about 1 minute ...\ngetAllCompanies query: curl -X GET 'https://127.0.0.1:9000/query/CrunchBasePre_2013/getAllCompanies'. Add -H \"Authorization: Bearer TOKEN\" if authentication is enabled.\n\n[=================================================================] 100% (1/1) \n\nBUILD SUCCESSFUL in 31s\n2 actionable tasks: 1 executed, 1 up-to-date\n\u001b[m"
    }
   ],
   "source": [
    "!gradle createGetAllCompanies --console=plain\n",
    "!gradle installGetAllCompanies --console=plain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyTigerGraph as tg \n",
    "import cfg\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pyTigerGraph as tg\n",
    "import dgl\n",
    "import networkx as nx\n",
    "from heapq import nlargest, nsmallest\n",
    "\n",
    "from gcn import GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Connection to Database and Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = tg.TigerGraphConnection(ipAddress=\"https://crunchml.i.tgcloud.io\", graphname=\"CrunchBasePre_2013\", password=cfg.password, apiToken=cfg.token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Edges Between Companies\n",
    "\n",
    "The cell below runs the query companyLinks, and then formats each edge into a tuple (src, destination). Unfortunately, due to both memory constraints as well as the imbalanced nature of the dataset, we will not use all of the edges in the graph, and instead sample nodes and then search this list for edges between the nodes.\n",
    "\n",
    "#### **Assumption Alert:** We oversimplify the graph here. The query returns pairs of companies that have something in common. This hurts accuracy (a lot). Where TigerGraph comes in is the ease of data extraction, as there are no JOIN operations to create these links between companies.\n",
    "* Note: It is possible to create a GCN that has multiple types of verticies, (known as a Relational Graph Convolutional Notebook) but it is more complex. A good way to get started is to simplify until you only have relations between the same type of thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('footballunited', 'phuser'), ('morningpapers', 'phuser'), ('phuser', 'footballunited')]\n"
    }
   ],
   "source": [
    "edges = [(thing[\"src\"], thing[\"dest\"]) for thing in conn.runInstalledQuery(\"companyLinks\", {}, sizeLimit=512000000, timeout=320000)[\"results\"][0][\"@@tupleRecords\"]]\n",
    "print(edges[:3])\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the List of IPOed Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Getting IPOed List\nGetting Non IPOed List\n"
    }
   ],
   "source": [
    "print(\"Getting IPOed List\")\n",
    "ipoed = list(set([thing[\"src\"] for thing in conn.runInstalledQuery(\"getAllIpo\", {}, sizeLimit=512000000, timeout=320000)[\"results\"][0][\"@@tupleRecords\"]]) - set(['']))\n",
    "print(\"Getting Non IPOed List\")\n",
    "nonipo = list(set([thing[\"src\"] for thing in conn.runInstalledQuery(\"getAllCompanies\", {}, sizeLimit=512000000, timeout=320000)[\"results\"][0][\"@@tupleRecords\"]]) - set(ipoed) - set(['']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Over-Sampled IPO Graph\n",
    "\n",
    "The code blocks below sample a number of nodes from each the IPOed list and the non-IPO list and determines what edges there are between the sampled nodes. Unfortunately, due to the large number of nodes in the complete graph, the number of edges in the sampled graph is quite small. This lack of edges contributes to the mediocre and highly variant performance of the following GCN. Other graph machine learning approaches such as node2vec might fair better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of IPOs:  1238\nTotal number of nodes:  2000\n2000\nComputing edges\n1105\n[('everex', 'nvidia'), ('helicos biosciences', 'bind therapeutics'), ('bind therapeutics', 'helicos biosciences')]\n"
    }
   ],
   "source": [
    "numberofnodes = 1000\n",
    "\n",
    "print(\"Number of IPOs: \", len(ipoed))\n",
    "ipoedsample = random.choices(ipoed, k=numberofnodes)\n",
    "noniposample = random.choices(nonipo, k=numberofnodes)\n",
    "print(\"Total number of nodes: \", len(noniposample)+len(ipoedsample))\n",
    "\n",
    "allNodes = noniposample+ipoedsample\n",
    "\n",
    "print(len(allNodes))\n",
    "\n",
    "\n",
    "finalEdges = []\n",
    "\n",
    "print(\"Computing edges\")\n",
    "for edge in edges:\n",
    "    if edge[0] in allNodes and edge[1] in allNodes:\n",
    "            finalEdges.append(edge)\n",
    "\n",
    "print(len(finalEdges))\n",
    "print(finalEdges[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of Edges:  1105\n[(364, 1980), (1694, 1771), (1771, 1694), (496, 1550), (496, 1688)]\n"
    }
   ],
   "source": [
    "compToNum = {} # translation dictionary for company name to number (for dgl)\n",
    "numToComp = {} # translation dictionary for number to company name\n",
    "\n",
    "numericalNodes = []\n",
    "\n",
    "for i in range(0, len(allNodes)):\n",
    "    compToNum[allNodes[i]] = i\n",
    "    numericalNodes.append(i)\n",
    "    numToComp[i] = allNodes[i]\n",
    "\n",
    "def createEdgeList(result): # returns tuple of number version of edge\n",
    "    fromKey = compToNum[result[0]]\n",
    "    toKey = compToNum[result[1]]\n",
    "    return (fromKey, toKey)\n",
    "\n",
    "edges = [createEdgeList(thing) for thing in finalEdges]\n",
    "print(\"Number of Edges: \", len(edges))\n",
    "print(edges[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.add_nodes_from(numericalNodes)\n",
    "g.add_edges_from(edges)\n",
    "\n",
    "\n",
    "G = dgl.DGLGraph(g) # Convert networkx graph to a graph that DGL can work on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding of Node Features\n",
    "We one-hot encode the features of the verticies in the graph. Feature assignment can be done a multitude of different ways, this is just the fastest and easiest.\n",
    "\n",
    "If you had a graph of documents for example, you could run doc2vec on those documents to create a feature vector and create the feature matrix by concatenating those together.\n",
    "\n",
    "Another possiblity is that you have a graph of songs, artists, albums, etc. and you could use tempo, max volume, minimum volume, length, and other numerical descriptions of the song to create the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[0., 0., 1.,  ..., 0., 0., 0.]])\n"
    }
   ],
   "source": [
    "G.ndata[\"feat\"] = torch.eye(G.number_of_nodes())\n",
    "\n",
    "print(G.nodes[2].data['feat'])\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Neural Network Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 200\n",
    "learningRate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Neural Network and Labelling Relevant Verticies\n",
    "\n",
    "Here, we create the GCN. A two-layered GCN appears to work better than deeper networks, and this is further corroborated by the fact [this](https://arxiv.org/abs/1609.02907) paper only used a two-layered one. We also label the wanted and unwanted verticies and setup the optimizer. Since the GCN is a semi-supervised algorithm, we do not label all of the nodes to their correct classes before training - only two are needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "compIPO = 0\n",
    "compNonIPO = 0\n",
    "i = 0\n",
    "while((not(compIPO) or not(compNonIPO)) and (i<G.number_of_nodes())):\n",
    "    if numToComp[i] in ipoed:\n",
    "        compIPO = i\n",
    "    else:\n",
    "        compNonIPO = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GCN(G.number_of_nodes(), 32, 2) #Two layer GCN\n",
    "inputs = G.ndata[\"feat\"]\n",
    "labeled_nodes = torch.tensor([compNonIPO, compIPO])  # only the liked movies and the disliked movies are labelled\n",
    "labels = torch.tensor([0, 1])  # their labels are different\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GCN\n",
    "\n",
    "Below is the training loop that actually trains the GCN. Unlike many traditional deep learning architectures, GCNs don't always need that much training or as large of data sets due to their exploitation of the *structure* of the data, as opposed to only the features of the data.\n",
    "* Note: due to the randomized initial values of the weights in the neural network and our lack of a very well-connected graph, sometimes models don't work very well, or their loss gets stuck at a relatively large number. If that happens, just stop and restart the training process (also rerun the cell above to reset the weights) and hope for better luck! Alternatively, you can run more epochs in hopes of eventually getting out of the rut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0 | Loss: 6.944e-01\nEpoch 1 | Loss: 6.940e-01\nEpoch 2 | Loss: 6.936e-01\nEpoch 3 | Loss: 6.934e-01\nEpoch 4 | Loss: 6.932e-01\nEpoch 5 | Loss: 6.932e-01\nEpoch 6 | Loss: 6.932e-01\nEpoch 7 | Loss: 6.932e-01\nEpoch 8 | Loss: 6.933e-01\nEpoch 9 | Loss: 6.933e-01\nEpoch 10 | Loss: 6.934e-01\nEpoch 11 | Loss: 6.934e-01\nEpoch 12 | Loss: 6.933e-01\nEpoch 13 | Loss: 6.933e-01\nEpoch 14 | Loss: 6.933e-01\nEpoch 15 | Loss: 6.932e-01\nEpoch 16 | Loss: 6.932e-01\nEpoch 17 | Loss: 6.932e-01\nEpoch 18 | Loss: 6.931e-01\nEpoch 19 | Loss: 6.931e-01\nEpoch 20 | Loss: 6.932e-01\nEpoch 21 | Loss: 6.932e-01\nEpoch 22 | Loss: 6.932e-01\nEpoch 23 | Loss: 6.932e-01\nEpoch 24 | Loss: 6.932e-01\nEpoch 25 | Loss: 6.932e-01\nEpoch 26 | Loss: 6.932e-01\nEpoch 27 | Loss: 6.932e-01\nEpoch 28 | Loss: 6.932e-01\nEpoch 29 | Loss: 6.932e-01\nEpoch 30 | Loss: 6.931e-01\nEpoch 31 | Loss: 6.931e-01\nEpoch 32 | Loss: 6.931e-01\nEpoch 33 | Loss: 6.932e-01\nEpoch 34 | Loss: 6.932e-01\nEpoch 35 | Loss: 6.932e-01\nEpoch 36 | Loss: 6.932e-01\nEpoch 37 | Loss: 6.932e-01\nEpoch 38 | Loss: 6.932e-01\nEpoch 39 | Loss: 6.932e-01\nEpoch 40 | Loss: 6.932e-01\nEpoch 41 | Loss: 6.932e-01\nEpoch 42 | Loss: 6.931e-01\nEpoch 43 | Loss: 6.931e-01\nEpoch 44 | Loss: 6.931e-01\nEpoch 45 | Loss: 6.931e-01\nEpoch 46 | Loss: 6.931e-01\nEpoch 47 | Loss: 6.932e-01\nEpoch 48 | Loss: 6.932e-01\nEpoch 49 | Loss: 6.932e-01\nEpoch 50 | Loss: 6.932e-01\nEpoch 51 | Loss: 6.931e-01\nEpoch 52 | Loss: 6.931e-01\nEpoch 53 | Loss: 6.931e-01\nEpoch 54 | Loss: 6.931e-01\nEpoch 55 | Loss: 6.931e-01\nEpoch 56 | Loss: 6.931e-01\nEpoch 57 | Loss: 6.931e-01\nEpoch 58 | Loss: 6.931e-01\nEpoch 59 | Loss: 6.931e-01\nEpoch 60 | Loss: 6.931e-01\nEpoch 61 | Loss: 6.931e-01\nEpoch 62 | Loss: 6.931e-01\nEpoch 63 | Loss: 6.931e-01\nEpoch 64 | Loss: 6.931e-01\nEpoch 65 | Loss: 6.931e-01\nEpoch 66 | Loss: 6.931e-01\nEpoch 67 | Loss: 6.931e-01\nEpoch 68 | Loss: 6.931e-01\nEpoch 69 | Loss: 6.931e-01\nEpoch 70 | Loss: 6.931e-01\nEpoch 71 | Loss: 6.931e-01\nEpoch 72 | Loss: 6.931e-01\nEpoch 73 | Loss: 6.931e-01\nEpoch 74 | Loss: 6.931e-01\nEpoch 75 | Loss: 6.931e-01\nEpoch 76 | Loss: 6.931e-01\nEpoch 77 | Loss: 6.931e-01\nEpoch 78 | Loss: 6.931e-01\nEpoch 79 | Loss: 6.931e-01\nEpoch 80 | Loss: 6.931e-01\nEpoch 81 | Loss: 6.931e-01\nEpoch 82 | Loss: 6.931e-01\nEpoch 83 | Loss: 6.931e-01\nEpoch 84 | Loss: 6.931e-01\nEpoch 85 | Loss: 6.931e-01\nEpoch 86 | Loss: 6.931e-01\nEpoch 87 | Loss: 6.931e-01\nEpoch 88 | Loss: 6.931e-01\nEpoch 89 | Loss: 6.931e-01\nEpoch 90 | Loss: 6.931e-01\nEpoch 91 | Loss: 6.931e-01\nEpoch 92 | Loss: 6.931e-01\nEpoch 93 | Loss: 6.931e-01\nEpoch 94 | Loss: 6.931e-01\nEpoch 95 | Loss: 6.931e-01\nEpoch 96 | Loss: 6.931e-01\nEpoch 97 | Loss: 6.931e-01\nEpoch 98 | Loss: 6.931e-01\nEpoch 99 | Loss: 6.931e-01\nEpoch 100 | Loss: 6.931e-01\nEpoch 101 | Loss: 6.931e-01\nEpoch 102 | Loss: 6.931e-01\nEpoch 103 | Loss: 6.931e-01\nEpoch 104 | Loss: 6.931e-01\nEpoch 105 | Loss: 6.931e-01\nEpoch 106 | Loss: 6.931e-01\nEpoch 107 | Loss: 6.931e-01\nEpoch 108 | Loss: 6.931e-01\nEpoch 109 | Loss: 6.931e-01\nEpoch 110 | Loss: 6.931e-01\nEpoch 111 | Loss: 6.931e-01\nEpoch 112 | Loss: 6.931e-01\nEpoch 113 | Loss: 6.931e-01\nEpoch 114 | Loss: 6.931e-01\nEpoch 115 | Loss: 6.931e-01\nEpoch 116 | Loss: 6.931e-01\nEpoch 117 | Loss: 6.931e-01\nEpoch 118 | Loss: 6.931e-01\nEpoch 119 | Loss: 6.931e-01\nEpoch 120 | Loss: 6.931e-01\nEpoch 121 | Loss: 6.931e-01\nEpoch 122 | Loss: 6.931e-01\nEpoch 123 | Loss: 6.931e-01\nEpoch 124 | Loss: 6.931e-01\nEpoch 125 | Loss: 6.931e-01\nEpoch 126 | Loss: 6.931e-01\nEpoch 127 | Loss: 6.931e-01\nEpoch 128 | Loss: 6.931e-01\nEpoch 129 | Loss: 6.931e-01\nEpoch 130 | Loss: 6.931e-01\nEpoch 131 | Loss: 6.931e-01\nEpoch 132 | Loss: 6.931e-01\nEpoch 133 | Loss: 6.931e-01\nEpoch 134 | Loss: 6.931e-01\nEpoch 135 | Loss: 6.931e-01\nEpoch 136 | Loss: 6.931e-01\nEpoch 137 | Loss: 6.931e-01\nEpoch 138 | Loss: 6.931e-01\nEpoch 139 | Loss: 6.931e-01\nEpoch 140 | Loss: 6.931e-01\nEpoch 141 | Loss: 6.931e-01\nEpoch 142 | Loss: 6.931e-01\nEpoch 143 | Loss: 6.931e-01\nEpoch 144 | Loss: 6.931e-01\nEpoch 145 | Loss: 6.931e-01\nEpoch 146 | Loss: 6.931e-01\nEpoch 147 | Loss: 6.931e-01\nEpoch 148 | Loss: 6.931e-01\nEpoch 149 | Loss: 6.931e-01\nEpoch 150 | Loss: 6.931e-01\nEpoch 151 | Loss: 6.931e-01\nEpoch 152 | Loss: 6.931e-01\nEpoch 153 | Loss: 6.931e-01\nEpoch 154 | Loss: 6.931e-01\nEpoch 155 | Loss: 6.931e-01\nEpoch 156 | Loss: 6.931e-01\nEpoch 157 | Loss: 6.931e-01\nEpoch 158 | Loss: 6.931e-01\nEpoch 159 | Loss: 6.931e-01\nEpoch 160 | Loss: 6.931e-01\nEpoch 161 | Loss: 6.931e-01\nEpoch 162 | Loss: 6.931e-01\nEpoch 163 | Loss: 6.931e-01\nEpoch 164 | Loss: 6.931e-01\nEpoch 165 | Loss: 6.931e-01\nEpoch 166 | Loss: 6.931e-01\nEpoch 167 | Loss: 6.931e-01\nEpoch 168 | Loss: 6.931e-01\nEpoch 169 | Loss: 6.931e-01\nEpoch 170 | Loss: 6.931e-01\nEpoch 171 | Loss: 6.931e-01\nEpoch 172 | Loss: 6.931e-01\nEpoch 173 | Loss: 6.931e-01\nEpoch 174 | Loss: 6.931e-01\nEpoch 175 | Loss: 6.931e-01\nEpoch 176 | Loss: 6.931e-01\nEpoch 177 | Loss: 6.931e-01\nEpoch 178 | Loss: 6.931e-01\nEpoch 179 | Loss: 6.931e-01\nEpoch 180 | Loss: 6.931e-01\nEpoch 181 | Loss: 6.931e-01\nEpoch 182 | Loss: 6.931e-01\nEpoch 183 | Loss: 6.931e-01\nEpoch 184 | Loss: 6.931e-01\nEpoch 185 | Loss: 6.931e-01\nEpoch 186 | Loss: 6.931e-01\nEpoch 187 | Loss: 6.931e-01\nEpoch 188 | Loss: 6.931e-01\nEpoch 189 | Loss: 6.931e-01\nEpoch 190 | Loss: 6.931e-01\nEpoch 191 | Loss: 6.931e-01\nEpoch 192 | Loss: 6.931e-01\nEpoch 193 | Loss: 6.931e-01\nEpoch 194 | Loss: 6.931e-01\nEpoch 195 | Loss: 6.931e-01\nEpoch 196 | Loss: 6.931e-01\nEpoch 197 | Loss: 6.931e-01\nEpoch 198 | Loss: 6.931e-01\nEpoch 199 | Loss: 6.931e-01\n"
    }
   ],
   "source": [
    "all_logits = []\n",
    "for epoch in range(numEpochs):\n",
    "    logits = net(G, inputs)\n",
    "    # we save the logits for visualization later\n",
    "    all_logits.append(logits.detach())\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    # we only compute loss for labeled nodes\n",
    "    loss = F.nll_loss(logp[labeled_nodes], labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch %d | Loss: %6.3e' % (epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True IPO:  271\nFalse IPO:  115\nTrue Non-IPO: 885\nFalse Non-IPO:  729\n"
    }
   ],
   "source": [
    "predictions = list(all_logits[numEpochs-1])\n",
    "predictIPO = []\n",
    "predictNonIPO = []\n",
    "\n",
    "a=0\n",
    "for company in predictions:\n",
    "    if company[1] >= company[0]:\n",
    "        predictIPO.append(numToComp[a])\n",
    "    else:\n",
    "        predictNonIPO.append(numToComp[a])\n",
    "    a += 1\n",
    "\n",
    "trueIPO = 0\n",
    "falseIPO = 0\n",
    "trueNonIPO = 0\n",
    "falseNonIPO = 0\n",
    "\n",
    "\n",
    "for prediction in predictIPO:\n",
    "    if prediction in ipoed:\n",
    "        trueIPO += 1\n",
    "    else:\n",
    "        falseIPO += 1\n",
    "\n",
    "print(\"True IPO: \", trueIPO)\n",
    "print(\"False IPO: \", falseIPO)\n",
    "\n",
    "for prediction in predictNonIPO:\n",
    "    if prediction in ipoed:\n",
    "        falseNonIPO += 1        \n",
    "    else:\n",
    "        trueNonIPO += 1\n",
    "print(\"True Non-IPO: \", trueNonIPO)\n",
    "print(\"False Non-IPO: \", falseNonIPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.578\n"
    }
   ],
   "source": [
    "accuracy = (trueNonIPO+trueIPO)/(len(predictions))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits\n",
    "<p><img alt=\"Picture of Parker Erickson\" height=\"150px\" src=\"https://avatars1.githubusercontent.com/u/9616171?s=460&v=4\" align=\"right\" hspace=\"20px\" vspace=\"20px\"></p>\n",
    "\n",
    "Demo/tutorial written by Parker Erickson, a student at the University of Minnesota pursuing a B.S. in Computer Science. His interests include graph databases, machine learning, travelling, playing the saxophone, and watching Minnesota Twins baseball. Feel free to reach out! Find him on:\n",
    "\n",
    "* LinkedIn: [https://www.linkedin.com/in/parker-erickson/](https://www.linkedin.com/in/parker-erickson/)\n",
    "* GitHub: [https://github.com/parkererickson](https://github.com/parkererickson)\n",
    "* Medium: [https://medium.com/@parker.erickson](https://medium.com/@parker.erickson)\n",
    "* Email: [parker.erickson30@gmail.com](parker.erickson30@gmail.com)\n",
    "----\n",
    "GCN Resources:\n",
    "* DGL Documentation: [https://docs.dgl.ai/](https://docs.dgl.ai/)\n",
    "* GCN paper by Kipf and Welling [https://arxiv.org/abs/1609.02907](https://arxiv.org/abs/1609.02907)\n",
    "* R-GCN paper: [https://arxiv.org/abs/1703.06103](https://arxiv.org/abs/1703.06103)\n",
    "---- \n",
    "Notebook adapted from: [https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html](https://docs.dgl.ai/en/latest/tutorials/basics/1_first.html)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit5e4270a542e54d6788076e0986af2669"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}